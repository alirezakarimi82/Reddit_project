{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vects = [CountVectorizer(), TfidfVectorizer()]\n",
    "models = [LogisticRegression(), KNeighborsClassifier(),\n",
    "          MultinomialNB(), RandomForestClassifier(random_state=42),\n",
    "          AdaBoostClassifier(random_state=42),\n",
    "          GradientBoostingClassifier(random_state=42),\n",
    "          SVC(random_state=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = []\n",
    "for vect in vects:\n",
    "    for model in models:\n",
    "        pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('model', model)])\n",
    "        pipes.append(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_vect = {'CountVectorizer': {'vect__stop_words': [None, 'english'],\n",
    "                                   'vect__ngram_range': [(1,1), (1,2)]},\n",
    "               'TfidfVectorizer': {'vect__stop_words': [None, 'english'],\n",
    "                                   'vect__ngram_range': [(1,1), (1,2)]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model = {'LogisticRegression': {'model__penalty': ['l1', 'l2'],\n",
    "                                       'model__C': np.logspace(-3, 3, 10)},\n",
    "                'KNeighborsClassifier': {'model__n_neighbors': [5, 7, 15],\n",
    "                                         'model__weights': ['uniform', 'distance']},\n",
    "                'MultinomialNB': {},\n",
    "                'RandomForestClassifier': {'model__n_estimators': [100, 150, 200],\n",
    "                                           'model__max_depth': [None, 2, 4]},\n",
    "                'AdaBoostClassifier': {'model__n_estimators': [100, 150, 200]},\n",
    "                'GradientBoostingClassifier': {'model__n_estimators': [100, 150, 200]},\n",
    "                'SVC': {'model__C': np.logspace(-2, 2, 5),\n",
    "                        'model__gamma': np.logspace(-4, 0, 5)}\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Vectorizer', 'Classifier',\n",
    "                           'best_params', 'train_recall', 'test_recall',\n",
    "                           'train_accuracy', 'test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipe in pipes:\n",
    "    Vectorizer = str(pipe.steps[0][1]).split('(')[0]\n",
    "    Classifier = str(pipe.steps[1][1]).split('(')[0]\n",
    "    \n",
    "    print('\\nGrid search using {} and {} ...\\n'.format(Vectorizer, Classifier))\n",
    "    \n",
    "    params = {**params_vect[Vectorizer], **params_model[Classifier]}\n",
    "    \n",
    "    grid = GridSearchCV(pipe, \n",
    "                    param_grid=params, \n",
    "                    cv = 5,\n",
    "                    scoring = 'accuracy',\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1,\n",
    "                    return_train_score = True)\n",
    "    \n",
    "    grid.fit(X_train, y_train);\n",
    "    \n",
    "    output = {}\n",
    "    output['Vectorizer'] = Vectorizer\n",
    "    output['Classifier'] = Classifier\n",
    "    output['best_params'] = grid.best_params_\n",
    "    output['train_accuracy'] = grid.best_score_\n",
    "    output['test_accuracy'] = grid.score(X_test, y_test)\n",
    "    output['train_recall'] = recall_score(y_train, grid.predict(X_train))\n",
    "    output['test_recall'] = recall_score(y_test, grid.predict(X_test))\n",
    "    \n",
    "    df = df.append(output, ignore_index=True)\n",
    "    \n",
    "    df.to_csv('./datasets/results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
